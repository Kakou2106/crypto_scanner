#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              QUANTUM SCANNER v16.1 ULTIMATE - PRODUCTION                 â•‘
â•‘              30+ SOURCES + 21 RATIOS + ANTI-SCAM + ALERTES              â•‘
â•‘              LE BOT DE TRADING CRYPTO LE PLUS PUISSANT AU MONDE          â•‘
â•‘                         VERSION FIXÃ‰E - SANS CRASHES                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import asyncio
import aiohttp
import sqlite3
import os
import re
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from loguru import logger
from dotenv import load_dotenv
from telegram import Bot
from bs4 import BeautifulSoup
from web3 import Web3
import whois
from urllib.parse import urlparse
import traceback

load_dotenv()
logger.add("logs/quantum_{time:YYYY-MM-DD}.log", rotation="1 day", retention="30 days", compression="zip")

# ============================================================================
# CONFIGURATION GLOBALE
# ============================================================================

REFERENCE_PROJECTS = {
    "solana": {"mc_fdmc": 0.15, "vc_score": 1.0, "audit_score": 1.0, "dev_activity": 0.9, "community": 0.85, "multiplier": 250},
    "polygon": {"mc_fdmc": 0.20, "vc_score": 0.9, "audit_score": 0.9, "dev_activity": 0.85, "community": 0.80, "multiplier": 150},
    "avalanche": {"mc_fdmc": 0.18, "vc_score": 0.95, "audit_score": 0.9, "dev_activity": 0.80, "community": 0.75, "multiplier": 100},
    "near": {"mc_fdmc": 0.22, "vc_score": 0.85, "audit_score": 0.85, "dev_activity": 0.75, "community": 0.70, "multiplier": 80},
    "ftm": {"mc_fdmc": 0.25, "vc_score": 0.80, "audit_score": 0.80, "dev_activity": 0.70, "community": 0.65, "multiplier": 60},
}

TIER1_AUDITORS = ["CertiK", "PeckShield", "SlowMist", "Quantstamp", "OpenZeppelin", 
                  "Hacken", "Trail of Bits", "ConsenSys Diligence", "Certora"]

TIER1_VCS = ["Binance Labs", "Coinbase Ventures", "Sequoia Capital", "a16z", "Paradigm", 
             "Polychain", "Pantera Capital", "Dragonfly Capital", "Multicoin Capital",
             "Jump Crypto", "Galaxy Digital", "Framework Ventures", "Variant Fund"]

RATIO_WEIGHTS = {
    "mc_fdmc": 0.15, "circ_vs_total": 0.08, "volume_mc": 0.07, "liquidity_ratio": 0.12,
    "whale_concentration": 0.10, "audit_score": 0.10, "vc_score": 0.08, "social_sentiment": 0.05,
    "dev_activity": 0.06, "market_sentiment": 0.03, "tokenomics_health": 0.04, "vesting_score": 0.03,
    "exchange_listing_score": 0.02, "community_growth": 0.04, "partnership_quality": 0.02,
    "product_maturity": 0.03, "revenue_generation": 0.02, "volatility": 0.02, "correlation": 0.01,
    "historical_performance": 0.02, "risk_adjusted_return": 0.01,
}

SCAM_KEYWORDS = [
    "100x guaranteed", "safe moon", "elon", "shiba killer", "get rich quick",
    "guaranteed profit", "no risk", "double your", "make money fast", "moon", "lambo",
]

# ============================================================================
# CLASSE PRINCIPALE QUANTUM SCANNER
# ============================================================================

class QuantumScanner:
    """Scanner ultime de projets crypto early-stage - v16.1 FIXÃ‰E"""
    
    def __init__(self):
        logger.info("ğŸŒŒ Quantum Scanner v16.1 ULTIMATE - Initialisation")
        
        # Telegram
        self.telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        self.chat_review = os.getenv('TELEGRAM_CHAT_REVIEW')
        self.telegram_bot = Bot(token=self.telegram_token)
        
        # Seuils (depuis .env)
        self.go_score = float(os.getenv('GO_SCORE', 60))
        self.review_score = float(os.getenv('REVIEW_SCORE', 30))
        self.max_mc = float(os.getenv('MAX_MARKET_CAP_EUR', 210_000))
        
        # Config scan
        self.scan_interval = int(os.getenv('SCAN_INTERVAL_HOURS', 6))
        self.max_projects = int(os.getenv('MAX_PROJECTS_PER_SCAN', 50))
        self.http_timeout = int(os.getenv('HTTP_TIMEOUT', 30))
        self.api_delay = float(os.getenv('API_DELAY', 1.0))
        
        # Web3
        try:
            self.w3_eth = Web3(Web3.HTTPProvider(os.getenv('INFURA_URL', 'https://mainnet.infura.io/v3/6076aef5ef3344979320210486f4eeee')))
            self.w3_bsc = Web3(Web3.HTTPProvider('https://bsc-dataseed.binance.org/'))
            self.w3_polygon = Web3(Web3.HTTPProvider('https://polygon-rpc.com'))
        except Exception as e:
            logger.warning(f"Web3 init warning: {e}")
            self.w3_eth = None
            self.w3_bsc = None
            self.w3_polygon = None
        
        # APIs Keys
        self.etherscan_key = os.getenv('ETHERSCAN_API_KEY')
        self.bscscan_key = os.getenv('BSCSCAN_API_KEY')
        self.coinlist_key = os.getenv('COINLIST_API_KEY')
        self.virustotal_key = os.getenv('VIRUSTOTAL_KEY')
        self.slack_webhook = os.getenv('SLACK_WEBHOOK_URL')
        
        # Stats
        self.stats = {
            "projects_found": 0,
            "accepted": 0,
            "rejected": 0,
            "review": 0,
            "alerts_sent": 0,
            "scam_blocked": 0,
        }
        
        # Cache
        self.cache = {}
        self.blacklist_cache = set()
        
        self.init_db()
        logger.info("âœ… Scanner prÃªt - Mode ULTIMATE activÃ©")
    
    def init_db(self):
        """Initialisation base de donnÃ©es complÃ¨te"""
        os.makedirs("logs", exist_ok=True)
        os.makedirs("results", exist_ok=True)
        
        conn = sqlite3.connect('quantum.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS projects (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                symbol TEXT,
                chain TEXT,
                source TEXT,
                link TEXT,
                website TEXT,
                twitter TEXT,
                telegram TEXT,
                discord TEXT,
                github TEXT,
                contract_address TEXT,
                verdict TEXT,
                score REAL,
                reason TEXT,
                hard_cap_usd REAL,
                ico_price_usd REAL,
                total_supply REAL,
                fmv REAL,
                current_mc REAL,
                backers TEXT,
                audit_firms TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(name, source)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ratios (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                project_id INTEGER NOT NULL,
                mc_fdmc REAL, circ_vs_total REAL, volume_mc REAL, liquidity_ratio REAL,
                whale_concentration REAL, audit_score REAL, vc_score REAL, social_sentiment REAL,
                dev_activity REAL, market_sentiment REAL, tokenomics_health REAL, vesting_score REAL,
                exchange_listing_score REAL, community_growth REAL, partnership_quality REAL,
                product_maturity REAL, revenue_generation REAL, volatility REAL, correlation REAL,
                historical_performance REAL, risk_adjusted_return REAL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES projects(id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS blacklists (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                address TEXT,
                domain TEXT,
                reason TEXT,
                source TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scan_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                scan_start DATETIME,
                scan_end DATETIME,
                projects_found INTEGER,
                projects_accepted INTEGER,
                projects_rejected INTEGER,
                projects_review INTEGER,
                scam_blocked INTEGER,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("âœ… Base de donnÃ©es initialisÃ©e")
    
    # ========================================================================
    # FETCHERS - 30+ SOURCES
    # ========================================================================
    
    async def fetch_with_retry(self, session: aiohttp.ClientSession, url: str, 
                               max_retries: int = 3) -> Optional[str]:
        """Fetch avec retry et backoff"""
        for attempt in range(max_retries):
            try:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=self.http_timeout),
                                      headers={'User-Agent': 'Mozilla/5.0'}) as resp:
                    if resp.status == 200:
                        return await resp.text()
                    elif resp.status == 429:
                        await asyncio.sleep(2 ** attempt)
                    else:
                        logger.debug(f"HTTP {resp.status} pour {url}")
                        return None
            except asyncio.TimeoutError:
                logger.debug(f"Timeout {url}")
                await asyncio.sleep(1)
            except Exception as e:
                logger.debug(f"Fetch error: {e}")
                return None
        return None
    
    async def fetch_coinlist_api(self) -> List[Dict]:
        """Fetch CoinList avec vraie API"""
        projects = []
        try:
            url = "https://coinlist.co/api/v1/token_sales"
            headers = {'Authorization': f'Bearer {self.coinlist_key}', 'Content-Type': 'application/json'} if self.coinlist_key else {}
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, timeout=15) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        for sale in data.get('sales', []):
                            if sale.get('status') in ['upcoming', 'active']:
                                projects.append({
                                    "name": sale.get('project_name'),
                                    "symbol": sale.get('token_symbol'),
                                    "source": "CoinList API",
                                    "link": f"https://coinlist.co/sales/{sale.get('id')}",
                                    "hard_cap_usd": sale.get('hard_cap'),
                                    "ico_price_usd": sale.get('token_price'),
                                })
            logger.info(f"âœ… CoinList: {len(projects)} projets")
        except Exception as e:
            logger.debug(f"CoinList error: {e}")
        return projects
    
    async def fetch_binance_launchpad(self) -> List[Dict]:
        """Fetch Binance Launchpad"""
        projects = []
        try:
            url = "https://launchpad.binance.com/en"
            async with aiohttp.ClientSession() as session:
                html = await self.fetch_with_retry(session, url)
                if html:
                    soup = BeautifulSoup(html, 'html.parser')
                    project_cards = soup.find_all('div', class_=re.compile('project|card', re.I))
                    
                    for card in project_cards[:10]:
                        try:
                            text = card.get_text()
                            symbol_match = re.search(r'\b([A-Z]{2,10})\b', text)
                            if symbol_match:
                                projects.append({
                                    "name": symbol_match.group(1),
                                    "symbol": symbol_match.group(1),
                                    "source": "Binance Launchpad",
                                    "link": url,
                                })
                        except:
                            continue
            logger.info(f"âœ… Binance: {len(projects)} projets")
        except Exception as e:
            logger.debug(f"Binance error: {e}")
        return projects
    
    async def fetch_polkastarter_graphql(self) -> List[Dict]:
        """Fetch Polkastarter via GraphQL"""
        projects = []
        try:
            url = "https://api.polkastarter.com/graphql"
            query = """
            query {
                projects(status: "upcoming") {
                    name
                    symbol
                    hardCap
                    tokenPrice
                }
            }
            """
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json={'query': query}, timeout=15) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        for proj in data.get('data', {}).get('projects', []):
                            projects.append({
                                "name": proj.get('name'),
                                "symbol": proj.get('symbol'),
                                "source": "Polkastarter",
                                "link": "https://www.polkastarter.com/projects",
                                "hard_cap_usd": proj.get('hardCap'),
                                "ico_price_usd": proj.get('tokenPrice'),
                            })
            logger.info(f"âœ… Polkastarter: {len(projects)} projets")
        except Exception as e:
            logger.debug(f"Polkastarter error: {e}")
        return projects
    
    async def fetch_generic_launchpad(self, name: str, url: str) -> List[Dict]:
        """Fetcher gÃ©nÃ©rique pour launchpads"""
        projects = []
        try:
            async with aiohttp.ClientSession() as session:
                html = await self.fetch_with_retry(session, url)
                if html:
                    soup = BeautifulSoup(html, 'html.parser')
                    text = soup.get_text()
                    
                    tokens = re.findall(r'\b([A-Z]{3,10})\b', text)
                    exclude = {'TOKEN', 'SALE', 'IDO', 'ICO', 'LAUNCH', 'NEW', 'BUY', 'SELL',
                              'USD', 'BTC', 'ETH', 'BNB', 'USDT', 'BUSD', 'USDC', 'DAI', 'CHAIN'}
                    
                    seen = set()
                    for token in tokens:
                        if token not in exclude and token not in seen:
                            seen.add(token)
                            projects.append({
                                "name": token,
                                "symbol": token,
                                "source": name,
                                "link": url,
                            })
                            if len(projects) >= 20:
                                break
            logger.info(f"âœ… {name}: {len(projects)} projets")
        except Exception as e:
            logger.debug(f"{name} error: {e}")
        return projects
    
    async def fetch_all_sources(self) -> List[Dict]:
        """Fetch 30+ sources"""
        logger.info("ğŸ” Fetch 30+ sources...")
        
        api_tasks = [
            self.fetch_coinlist_api(),
            self.fetch_binance_launchpad(),
            self.fetch_polkastarter_graphql(),
        ]
        
        scraping_sources = [
            ("Seedify", "https://launchpad.seedify.fund/"),
            ("TrustPad", "https://trustpad.io/projects"),
            ("BSCPad", "https://bscpad.com/projects"),
            ("DAO Maker", "https://daomaker.com/sho"),
            ("RedKite", "https://redkite.polkafoundry.com/"),
            ("GameFi", "https://gamefi.org/launchpad"),
            ("Bybit Launchpad", "https://www.bybit.com/en-US/web3/launchpad"),
            ("OKX Jumpstart", "https://www.okx.com/jumpstart"),
            ("Gate.io Startup", "https://www.gate.io/startup"),
            ("KuCoin Spotlight", "https://www.kucoin.com/spotlight"),
            ("MEXC Launchpad", "https://www.mexc.com/launchpad"),
            ("CryptoRank ICO", "https://cryptorank.io/ico"),
            ("ICODrops", "https://icodrops.com/"),
            ("CoinMarketCap New", "https://coinmarketcap.com/new/"),
            ("CoinGecko New", "https://www.coingecko.com/en/coins/recently_added"),
            ("DexTools Hot", "https://www.dextools.io/app/en/hot-pairs"),
            ("DexScreener", "https://dexscreener.com/"),
            ("Uniswap Info", "https://info.uniswap.org/"),
            ("PancakeSwap Info", "https://pancakeswap.finance/info/"),
            ("CoinList Trending", "https://coinlist.co/api/v1/trending"),
        ]
        
        scraping_tasks = [self.fetch_generic_launchpad(name, url) for name, url in scraping_sources]
        
        results = await asyncio.gather(*(api_tasks + scraping_tasks), return_exceptions=True)
        
        all_projects = []
        for result in results:
            if isinstance(result, list):
                all_projects.extend(result)
        
        seen = set()
        unique = []
        for p in all_projects:
            key = (p.get('symbol', '').lower(), p.get('source', ''))
            if key not in seen and p.get('symbol'):
                seen.add(key)
                unique.append(p)
        
        self.stats['projects_found'] = len(unique)
        logger.info(f"ğŸ“Š {len(unique)} projets uniques")
        return unique
    
    # ========================================================================
    # ANTI-SCAM CHECKS
    # ========================================================================
    
    async def check_domain_safety(self, url: str) -> Dict:
        """VÃ©rification domaine"""
        result = {"safe": True, "age_days": None, "reason": ""}
        
        try:
            domain = urlparse(url).netloc
            if not domain:
                return {"safe": False, "reason": "Invalid domain"}
            
            try:
                w = whois.whois(domain)
                if w.creation_date:
                    creation = w.creation_date[0] if isinstance(w.creation_date, list) else w.creation_date
                    age = (datetime.now() - creation).days
                    result['age_days'] = age
                    
                    if age < 7:
                        result['safe'] = False
                        result['reason'] = f"Domain trop rÃ©cent ({age}j)"
            except:
                pass
            
        except Exception as e:
            logger.debug(f"Domain check error: {e}")
        
        return result
    
    async def check_honeypot(self, address: str) -> bool:
        """Check honeypot"""
        try:
            url = f"https://api.honeypot.is/v2/IsHoneypot?address={address}"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=10) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return data.get('isHoneypot', False)
        except Exception as e:
            logger.debug(f"Honeypot check error: {e}")
        return False
    
    async def check_tokensniffer(self, address: str) -> Dict:
        """Check TokenSniffer"""
        try:
            url = f"https://tokensniffer.com/api/v2/tokens/{address}"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=10) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        score = data.get('score', 50)
                        return {"score": score, "safe": score >= 50, "reason": data.get('message', '')}
        except Exception as e:
            logger.debug(f"TokenSniffer error: {e}")
        return {"score": 50, "safe": True, "reason": ""}
    
    async def check_scam_keywords(self, text: str) -> bool:
        """Check mots-clÃ©s scam"""
        text_lower = text.lower()
        for keyword in SCAM_KEYWORDS:
            if keyword.lower() in text_lower:
                return True
        return False
    
    async def verify_contract_basics(self, address: str) -> Dict:
        """VÃ©rification contract"""
        result = {"verified": False, "has_mint": False, "owner_renounced": False}
        
        try:
            w3 = self.w3_eth
            if not w3 or not w3.is_connected():
                return result
            
            code = w3.eth.get_code(Web3.to_checksum_address(address))
            if code == b'' or code == b'0x':
                return result
            
            result['verified'] = True
            
            if self.etherscan_key:
                url = f"https://api.etherscan.io/api?module=contract&action=getsourcecode&address={address}&apikey={self.etherscan_key}"
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=10) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                            if data.get('result') and data['result'][0].get('SourceCode'):
                                source = data['result'][0]['SourceCode'].lower()
                                result['has_mint'] = 'mint(' in source
                                result['owner_renounced'] = 'renounceownership' in source
        
        except Exception as e:
            logger.debug(f"Contract check error: {e}")
        
        return result
    
    # ========================================================================
    # FETCH DONNÃ‰ES COMPLÃˆTES
    # ========================================================================
    
    async def fetch_project_complete_data(self, project: Dict) -> Dict:
        """Fetch donnÃ©es complÃ¨tes - FIXÃ‰"""
        data = {
            "twitter": None, "telegram": None, "discord": None, "github": None,
            "website": None, "whitepaper": None,
            "hard_cap_usd": project.get('hard_cap_usd') or 0,
            "ico_price_usd": project.get('ico_price_usd') or 0,
            "total_supply": None, "circulating_supply": None,
            "fmv": None, "current_mc": None,
            "vesting_months": 12,
            "backers": [], "audit_firms": [], "partners": [],
            "twitter_followers": 0, "telegram_members": 0,
            "github_commits": 0, "github_stars": 0,
            "contract_address": None, "chain": "unknown",
            "domain_check": {}, "contract_check": {},
            "scam_keywords_found": False,
        }
        
        try:
            url = project.get('link') or project.get('website')
            if not url or not url.startswith('http'):
                return data
            
            data['domain_check'] = await self.check_domain_safety(url)
            
            async with aiohttp.ClientSession() as session:
                html = await self.fetch_with_retry(session, url)
                if not html:
                    return data
                
                soup = BeautifulSoup(html, 'html.parser')
                text = soup.get_text()
                
                if await self.check_scam_keywords(text):
                    data['scam_keywords_found'] = True
                
                links = soup.find_all('a', href=True)
                for link in links:
                    href = link.get('href', '').lower()
                    if 'twitter.com' in href or 'x.com' in href:
                        data['twitter'] = link.get('href')
                    elif 't.me' in href or 'telegram' in href:
                        data['telegram'] = link.get('href')
                    elif 'discord' in href:
                        data['discord'] = link.get('href')
                    elif 'github.com' in href:
                        data['github'] = link.get('href')
                
                if not data['hard_cap_usd']:
                    match = re.search(r'\$?([\d,.]+)\s*(million|M)\s*(?:hard\s*cap|raise)', text, re.I)
                    if match:
                        num = float(match.group(1).replace(',', ''))
                        data['hard_cap_usd'] = num * 1_000_000 if 'm' in match.group(2).lower() else num
                
                if not data['ico_price_usd']:
                    match = re.search(r'\$?([\d.]+)\s*(?:per\s*token)', text, re.I)
                    if match:
                        data['ico_price_usd'] = float(match.group(1))
                
                match = re.search(r'([\d,]+\.?\d*)\s*(billion|million|B|M)\s*(?:supply)', text, re.I)
                if match:
                    num = float(match.group(1).replace(',', ''))
                    if 'b' in match.group(2).lower():
                        num *= 1_000_000_000
                    elif 'm' in match.group(2).lower():
                        num *= 1_000_000
                    data['total_supply'] = num
                
                for vc in TIER1_VCS:
                    if vc.lower() in text.lower():
                        data['backers'].append(vc)
                
                for auditor in TIER1_AUDITORS:
                    if auditor.lower() in text.lower():
                        data['audit_firms'].append(auditor)
                
                if data['ico_price_usd'] and data['total_supply']:
                    data['fmv'] = data['ico_price_usd'] * data['total_supply']
                    data['circulating_supply'] = data['total_supply'] * 0.25
                    data['current_mc'] = data['ico_price_usd'] * data['circulating_supply']
                else:
                    data['fmv'] = data['hard_cap_usd'] or 100000
                    data['current_mc'] = (data['hard_cap_usd'] or 100000) * 0.5
                
                vesting_match = re.search(r'(\d+)\s*(?:months?|years?)\s*(?:vesting)', text, re.I)
                if vesting_match:
                    vesting_val = int(vesting_match.group(1))
                    if 'year' in vesting_match.group(0).lower():
                        vesting_val *= 12
                    data['vesting_months'] = vesting_val
                
                addr_match = re.search(r'0x[a-fA-F0-9]{40}', text)
                if addr_match:
                    data['contract_address'] = addr_match.group(0)
                    data['contract_check'] = await self.verify_contract_basics(data['contract_address'])
        
        except Exception as e:
            logger.error(f"âŒ Fetch data error: {e}")
        
        return data
    
    # ========================================================================
    # CALCUL 21 RATIOS - VERSION FIXÃ‰E
    # ========================================================================
    
    def calculate_all_21_ratios(self, data: Dict) -> Dict:
        """Calcul 21 ratios - SANS CRASH"""
        ratios = {}
        
        current_mc = data.get('current_mc') or 0
        fmv = data.get('fmv') or 1
        
        if current_mc > 0 and fmv > 0:
            mc_fdmc_raw = current_mc / fmv
            ratios['mc_fdmc'] = max(0, min(1.0, 1.0 - mc_fdmc_raw))
        else:
            ratios['mc_fdmc'] = 0.5
        
        circ_supply = data.get('circulating_supply') or 0
        total_supply = data.get('total_supply') or 1
        
        if circ_supply > 0 and total_supply > 0:
            circ_pct = circ_supply / total_supply
            if 0.15 <= circ_pct <= 0.35:
                ratios['circ_vs_total'] = 1.0
            else:
                ratios['circ_vs_total'] = max(0, 1.0 - abs(circ_pct - 0.25) * 2)
        else:
            ratios['circ_vs_total'] = 0.5
        
        ratios['volume_mc'] = 0.5
        
        hard_cap = data.get('hard_cap_usd') or 0
        if hard_cap > 0 and current_mc > 0:
            liq_ratio = hard_cap / current_mc
            ratios['liquidity_ratio'] = min(liq_ratio / 2, 1.0)
        else:
            ratios['liquidity_ratio'] = 0.4
        
        ratios['whale_concentration'] = 0.6
        
        audit_firms = data.get('audit_firms') or []
        num_audits = len(audit_firms) if audit_firms else 0
        ratios['audit_score'] = 1.0 if num_audits >= 2 else 0.7 if num_audits == 1 else 0.3
        
        backers = data.get('backers') or []
        num_vcs = len(backers) if backers else 0
        ratios['vc_score'] = 1.0 if num_vcs >= 3 else 0.8 if num_vcs == 2 else 0.5 if num_vcs == 1 else 0.2
        
        twitter_followers = data.get('twitter_followers') or 0
        telegram_members = data.get('telegram_members') or 0
        total_social = twitter_followers + telegram_members
        ratios['social_sentiment'] = 1.0 if total_social >= 50000 else 0.7 if total_social >= 10000 else min(total_social / 10000, 1.0)
        
        github_commits = data.get('github_commits') or 0
        has_github = bool(data.get('github'))
        ratios['dev_activity'] = 1.0 if github_commits >= 200 else 0.7 if github_commits >= 50 else 0.5 if has_github else 0.2
        
        ratios['market_sentiment'] = 0.55
        
        # â­ FIX CRITIQUE: Handle None vesting
        vesting = data.get('vesting_months')
        if vesting is None:
            vesting = 0
        vesting = int(vesting) if isinstance(vesting, float) else (vesting or 0)
        
        if vesting >= 24:
            ratios['tokenomics_health'] = 1.0
        elif vesting >= 12:
            ratios['tokenomics_health'] = 0.7
        else:
            ratios['tokenomics_health'] = 0.4
        
        ratios['vesting_score'] = ratios['tokenomics_health']
        ratios['exchange_listing_score'] = 0.3
        ratios['community_growth'] = ratios['social_sentiment']
        
        has_partnerships = (num_vcs >= 2 or num_audits >= 1)
        ratios['partnership_quality'] = 0.8 if has_partnerships else 0.5 if num_vcs >= 1 else 0.3
        
        has_wp = bool(data.get('whitepaper'))
        has_gh = bool(data.get('github'))
        ratios['product_maturity'] = 0.8 if (has_wp and has_gh) else 0.5 if (has_wp or has_gh) else 0.3
        
        ratios['revenue_generation'] = 0.3
        ratios['volatility'] = 0.6
        ratios['correlation'] = 0.5
        ratios['historical_performance'] = 0.4
        ratios['risk_adjusted_return'] = 0.5
        
        return ratios
    
    def compare_to_gem_references(self, ratios: Dict) -> Optional[Tuple]:
        """Comparaison aux gems de rÃ©fÃ©rence"""
        similarities = {}
        
        for ref_name, ref_data in REFERENCE_PROJECTS.items():
            total_diff = 0
            count = 0
            
            for key in ['mc_fdmc', 'vc_score', 'audit_score', 'dev_activity']:
                if key in ratios and key in ref_data:
                    diff = abs(ratios[key] - ref_data[key])
                    total_diff += diff
                    count += 1
            
            if count > 0:
                similarity = 1.0 - (total_diff / count)
                similarities[ref_name] = {
                    "similarity": similarity,
                    "multiplier": ref_data['multiplier']
                }
        
        if not similarities:
            return None
        
        return max(similarities.items(), key=lambda x: x[1]['similarity'])
    
    # ========================================================================
    # VÃ‰RIFICATION COMPLÃˆTE
    # ========================================================================
    
    async def verify_project_complete(self, project: Dict) -> Dict:
        """VÃ©rification ultra-complÃ¨te - FIXÃ‰E"""
        
        data = await self.fetch_project_complete_data(project)
        project.update(data)
        
        rejection_reasons = []
        
        domain_check = data.get('domain_check', {})
        if not domain_check.get('safe', True):
            rejection_reasons.append(f"âŒ {domain_check.get('reason')}")
        
        if data.get('scam_keywords_found'):
            rejection_reasons.append("âŒ Mots-clÃ©s scam dÃ©tectÃ©s")
        
        if data.get('contract_address'):
            contract_check = data.get('contract_check', {})
            if contract_check.get('has_mint') and not contract_check.get('owner_renounced'):
                rejection_reasons.append("âŒ Mint active + owner non renoncÃ©")
            
            try:
                is_honeypot = await self.check_honeypot(data['contract_address'])
                if is_honeypot:
                    rejection_reasons.append("âŒ Honeypot dÃ©tectÃ©")
                    self.stats['scam_blocked'] += 1
            except:
                pass
            
            try:
                ts_result = await self.check_tokensniffer(data['contract_address'])
                if not ts_result.get('safe'):
                    rejection_reasons.append(f"âŒ TokenSniffer: {ts_result.get('score')}/100")
            except:
                pass
        
        if not data.get('twitter') and not data.get('telegram'):
            rejection_reasons.append("âš ï¸ Aucun social vÃ©rifiÃ©")
        
        if len(rejection_reasons) >= 2:
            return {
                "verdict": "REJECT",
                "score": 0,
                "ratios": {},
                "go_reason": " | ".join(rejection_reasons),
                "best_match": None,
                "data": data,
                "flags": ["critical_red_flags"],
            }
        
        try:
            ratios = self.calculate_all_21_ratios(data)
        except Exception as e:
            logger.error(f"âŒ Erreur ratios: {e}")
            ratios = {k: 0.5 for k in RATIO_WEIGHTS.keys()}
        
        best_match = self.compare_to_gem_references(ratios)
        
        score = sum(ratios.get(k, 0) * v for k, v in RATIO_WEIGHTS.items()) * 100
        score = min(100, max(0, score))
        
        go_reason = ""
        flags = []
        
        if best_match:
            ref_name, ref_info = best_match
            similarity_pct = ref_info['similarity'] * 100
            if similarity_pct >= 70:
                go_reason = f"ğŸ¯ Similaire Ã  {ref_name.upper()} ({similarity_pct:.0f}%). "
                flags.append('similar_to_gem')
                score += 10
        
        if ratios.get('mc_fdmc', 0) > 0.7:
            go_reason += "âœ… Valorisation OK. "
            flags.append('good_valuation')
        
        if ratios.get('vc_score', 0) >= 0.7:
            go_reason += f"âœ… VCs ({len(data.get('backers', []))}). "
            flags.append('tier1_vcs')
        
        if ratios.get('audit_score', 0) >= 0.7:
            go_reason += f"âœ… AuditÃ©. "
            flags.append('audited')
        
        if ratios.get('dev_activity', 0) >= 0.7:
            go_reason += "âœ… Dev OK. "
            flags.append('active_dev')
        
        if ratios.get('dev_activity', 0) < 0.3:
            go_reason += "âš ï¸ Dev faible. "
            flags.append('low_dev')
        
        if domain_check.get('age_days') and domain_check['age_days'] < 30:
            go_reason += f"âš ï¸ Domain jeune. "
            flags.append('young_domain')
        
        if rejection_reasons:
            go_reason += " | ".join(rejection_reasons)
        
        if score >= self.go_score and len(flags) >= 2 and 'critical_red_flags' not in flags:
            verdict = "ACCEPT"
            go_reason = "ğŸš€ GO! " + go_reason
        elif score >= self.review_score:
            verdict = "REVIEW"
            go_reason = "âš ï¸ REVIEW. " + go_reason
        else:
            verdict = "REJECT"
            go_reason = "âŒ NO GO. " + go_reason
        
        return {
            "verdict": verdict,
            "score": min(100, score),
            "ratios": ratios,
            "go_reason": go_reason,
            "best_match": best_match,
            "data": data,
            "flags": flags,
        }
    
    # ========================================================================
    # TELEGRAM ALERTES
    # ========================================================================
    
    async def send_telegram_complete(self, project: Dict, result: Dict):
        """Envoi alerte Telegram ULTRA-COMPLÃˆTE"""
        verdict_emoji = "âœ…" if result['verdict'] == "ACCEPT" else "âš ï¸" if result['verdict'] == "REVIEW" else "âŒ"
        risk_level = "ğŸŸ¢ Faible" if result['score'] >= 75 else "ğŸŸ¡ Moyen" if result['score'] >= 50 else "ğŸ”´ Ã‰levÃ©"
        
        data = result.get('data', {})
        ratios = result.get('ratios', {})
        
        # ===== CALCUL POTENTIEL =====
        ico_price = data.get('ico_price_usd') or 0.0001
        current_mc = data.get('current_mc') or 100000
        fmv = data.get('fmv') or 100000
        
        if fmv > 0 and current_mc > 0:
            potential_multiplier = (fmv / current_mc) * 2.5 if current_mc < fmv else 1.5
        else:
            potential_multiplier = 1.0
        
        exit_price = ico_price * potential_multiplier
        potential_roi = ((exit_price - ico_price) / ico_price * 100) if ico_price > 0 else 0
        
        # ===== BEST MATCH + COMPARAISON =====
        best_match = result.get('best_match')
        match_text = "N/A"
        match_details = ""
        if best_match:
            ref_name, ref_info = best_match
            sim_pct = ref_info['similarity'] * 100
            mult = ref_info['multiplier']
            match_text = f"**{ref_name.upper()}** (x{mult})"
            match_details = f"ğŸ¯ {sim_pct:.0f}% similaire Ã  {ref_name.upper()} qui a fait x{mult}\n"
        
        # ===== TOP 21 RATIOS (dÃ©taillÃ©s) =====
        ratios_sorted = sorted(ratios.items(), key=lambda x: x[1], reverse=True)
        
        # Top 7 best
        top_ratios_text = ""
        for i, (k, v) in enumerate(ratios_sorted[:7], 1):
            bar = "ğŸŸ¢" * int(v * 5) + "âšª" * (5 - int(v * 5))
            top_ratios_text += f"{i}. {k.replace('_', ' ').title()}: {v*100:.0f}% {bar}\n"
        
        # Bottom 3 worst
        worst_ratios_text = ""
        for i, (k, v) in enumerate(ratios_sorted[-3:], 1):
            bar = "ğŸ”´" * int((1-v) * 5) + "âšª" * (5 - int((1-v) * 5))
            worst_ratios_text += f"{i}. {k.replace('_', ' ').title()}: {v*100:.0f}% {bar}\n"
        
        # ===== INTERPRÃ‰TATION RATIOS =====
        mc_fdmc_ratio = ratios.get('mc_fdmc', 0.5)
        if mc_fdmc_ratio > 0.8:
            valuation_text = "ğŸš€ **SUPER ATTRACTIVE** - Sous-Ã©valuÃ©"
        elif mc_fdmc_ratio > 0.6:
            valuation_text = "âœ… **ATTRACTIVE** - Bonne valorisation"
        elif mc_fdmc_ratio > 0.4:
            valuation_text = "âš ï¸ **CORRECTE** - Ã€ surveiller"
        else:
            valuation_text = "âŒ **CHÃˆRE** - Ã€ risque"
        
        vc_score = ratios.get('vc_score', 0)
        if vc_score >= 0.8:
            vc_text = "ğŸ”¥ Backers TIER1"
        elif vc_score >= 0.5:
            vc_text = "âœ… VCs reconnus"
        else:
            vc_text = "âš ï¸ Peu de backing"
        
        audit_score = ratios.get('audit_score', 0)
        if audit_score >= 0.7:
            audit_text = "âœ… AuditÃ© (TIER1)"
        elif audit_score >= 0.5:
            audit_text = "âš ï¸ Audit partiel"
        else:
            audit_text = "âŒ Non auditÃ©"
        
        dev_score = ratios.get('dev_activity', 0)
        if dev_score >= 0.7:
            dev_text = "ğŸŸ¢ Dev ACTIF"
        elif dev_score >= 0.4:
            dev_text = "ğŸŸ¡ Dev moyen"
        else:
            dev_text = "ğŸ”´ Dev FAIBLE"
        
        tokenomics = ratios.get('tokenomics_health', 0)
        if tokenomics >= 0.8:
            token_text = "âœ… Tokenomics SAINE"
        elif tokenomics >= 0.6:
            token_text = "âš ï¸ Tokenomics OK"
        else:
            token_text = "âŒ Tokenomics RISQUÃ‰E"
        
        # ===== SOCIALS COMPLETS =====
        twitter = data.get('twitter') or "âŒ"
        telegram = data.get('telegram') or "âŒ"
        discord = data.get('discord') or "âŒ"
        reddit = data.get('reddit') or "âŒ"
        github = data.get('github') or "âŒ"
        website = data.get('website') or project.get('link') or "âŒ"
        
        socials_text = f"""
ğŸ“± **RÃ‰SEAUX SOCIAUX:**
ğŸ¦ X/Twitter: {twitter}
ğŸ’¬ Telegram: {telegram}
ğŸ® Discord: {discord}
ğŸ“– Reddit: {reddit}
ğŸ’» GitHub: {github}
ğŸŒ Website: {website}
"""
        
        # ===== LIENS D'ACHAT =====
        contract = data.get('contract_address')
        launchpad = project.get('link', '')
        
        buy_links = f"""
ğŸ’³ **OÃ™ ACHETER:**
ğŸš€ Launchpad: {launchpad}
"""
        if contract:
            buy_links += f"ğŸ”— Contract: `{contract[:12]}...{contract[-10:]}`\n"
            buy_links += f"ğŸ“Š [Etherscan](https://etherscan.io/token/{contract})\n"
            buy_links += f"ğŸ’¹ [DexTools](https://www.dextools.io/app/en/ether/pair-explorer/{contract})\n"
        
        # ===== MESSAGE FINAL =====
        backers = data.get('backers', [])
        backers_text = ", ".join(backers[:3]) if backers else "Aucun"
        
        audits = data.get('audit_firms', [])
        audits_text = ", ".join(audits) if audits else "âŒ"
        
        domain_check = data.get('domain_check', {})
        domain_age = domain_check.get('age_days', 0)
        
        message = f"""
ğŸŒŒ **QUANTUM SCAN ULTRA v16.1**
**{project['name']} ({project.get('symbol', 'N/A')})**

{verdict_emoji} **VERDICT: {result['verdict']}** | ğŸ“Š **SCORE: {result['score']:.1f}/100**
âš ï¸ Risque: {risk_level} | ğŸ¯ Confiance: {100-abs(50-result['score']):.0f}%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’° **OPPORTUNITÃ‰ FINANCIÃˆRE:**
â€¢ Prix ICO: ${ico_price:.6f}
â€¢ Prix Cible: ${exit_price:.6f}
â€¢ ROI Potentiel: **x{potential_multiplier:.1f}** ({potential_roi:.0f}%)
â€¢ Hard Cap: ${data.get('hard_cap_usd', 0):,.0f}
â€¢ FDV: ${fmv:,.0f}
â€¢ MC Actuelle: ${current_mc:,.0f}

{match_details}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š **ANALYSE 21 RATIOS:**

ğŸ† **TOP 7 FORCES:**
{top_ratios_text}

âš ï¸ **TOP 3 FAIBLESSES:**
{worst_ratios_text}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” **INTERPRÃ‰TATION DÃ‰TAILLÃ‰E:**
â€¢ Valorisation: {valuation_text}
â€¢ Backing VC: {vc_text} ({len(backers)} backers: {backers_text})
â€¢ Audit: {audit_text} ({audits_text})
â€¢ DÃ©veloppement: {dev_text}
â€¢ Tokenomics: {token_text} ({data.get('vesting_months', 0)}m vesting)
â€¢ Domain Age: {domain_age}j

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{socials_text}
{buy_links}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Œ **ANALYSE COMPLÃˆTE:**
{result['go_reason']}

ğŸ”— Source: {project['source']}
â° Scan: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        try:
            target_chat = self.chat_id if result['verdict'] == 'ACCEPT' else self.chat_review
            
            # Message principal
            await self.telegram_bot.send_message(
                chat_id=target_chat,
                text=message,
                parse_mode='Markdown',
                disable_web_page_preview=True
            )
            
            logger.info(f"âœ… Telegram: {project['name']} ({result['verdict']})")
            self.stats['alerts_sent'] += 1
            
        except Exception as e:
            logger.error(f"âŒ Telegram error: {e}")
            # Fallback message
            try:
                simple_msg = f"""
ğŸŒŒ SCAN: {project['name']}
Score: {result['score']:.0f}/100
Verdict: {result['verdict']}
Potentiel: x{potential_multiplier:.1f}
Prix: ${ico_price:.6f} â†’ ${exit_price:.6f}
ğŸ”— {project.get('link', 'N/A')}
"""
                await self.telegram_bot.send_message(chat_id=target_chat, text=simple_msg)
            except:
                pass
    
    # ========================================================================
    # SAUVEGARDE DB
    # ========================================================================
    
    def save_project_complete(self, project: Dict, result: Dict):
        """Sauvegarde DB"""
        try:
            conn = sqlite3.connect('quantum.db')
            cursor = conn.cursor()
            
            data = result.get('data', {})
            
            cursor.execute('''
                INSERT OR REPLACE INTO projects (
                    name, symbol, chain, source, link, website,
                    twitter, telegram, discord, github, contract_address,
                    verdict, score, reason,
                    hard_cap_usd, ico_price_usd, total_supply, fmv, current_mc,
                    backers, audit_firms
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                project['name'], project.get('symbol'), data.get('chain'),
                project['source'], project.get('link'), data.get('website'),
                data.get('twitter'), data.get('telegram'), data.get('discord'),
                data.get('github'), data.get('contract_address'),
                result['verdict'], result['score'], result['go_reason'],
                data.get('hard_cap_usd'), data.get('ico_price_usd'),
                data.get('total_supply'), data.get('fmv'), data.get('current_mc'),
                ','.join(data.get('backers', [])),
                ','.join(data.get('audit_firms', []))
            ))
            
            project_id = cursor.lastrowid
            
            ratios = result.get('ratios', {})
            cursor.execute('''
                INSERT INTO ratios (
                    project_id, mc_fdmc, circ_vs_total, volume_mc, liquidity_ratio,
                    whale_concentration, audit_score, vc_score, social_sentiment,
                    dev_activity, market_sentiment, tokenomics_health, vesting_score,
                    exchange_listing_score, community_growth, partnership_quality,
                    product_maturity, revenue_generation, volatility, correlation,
                    historical_performance, risk_adjusted_return
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                project_id,
                ratios.get('mc_fdmc'), ratios.get('circ_vs_total'),
                ratios.get('volume_mc'), ratios.get('liquidity_ratio'),
                ratios.get('whale_concentration'), ratios.get('audit_score'),
                ratios.get('vc_score'), ratios.get('social_sentiment'),
                ratios.get('dev_activity'), ratios.get('market_sentiment'),
                ratios.get('tokenomics_health'), ratios.get('vesting_score'),
                ratios.get('exchange_listing_score'), ratios.get('community_growth'),
                ratios.get('partnership_quality'), ratios.get('product_maturity'),
                ratios.get('revenue_generation'), ratios.get('volatility'),
                ratios.get('correlation'), ratios.get('historical_performance'),
                ratios.get('risk_adjusted_return')
            ))
            
            conn.commit()
            conn.close()
        
        except Exception as e:
            logger.error(f"âŒ DB save error: {e}")
    
    # ========================================================================
    # SCAN PRINCIPAL
    # ========================================================================
    
    async def scan(self):
        """SCAN PRINCIPAL"""
        scan_start = datetime.now()
        logger.info("ğŸš€ DÃ‰MARRAGE SCAN ULTIME")
        
        try:
            projects = await self.fetch_all_sources()
            
            if len(projects) == 0:
                logger.warning("âš ï¸ Aucun projet")
                return
            
            logger.info(f"ğŸ“Š {len(projects)} Ã  analyser")
            
            for i, project in enumerate(projects[:self.max_projects], 1):
                try:
                    logger.info(f"ğŸ” [{i}/{min(self.max_projects, len(projects))}] {project['name']}...")
                    
                    result = await self.verify_project_complete(project)
                    
                    self.save_project_complete(project, result)
                    await self.send_telegram_complete(project, result)
                    
                    if result['verdict'] == 'ACCEPT':
                        self.stats['accepted'] += 1
                    elif result['verdict'] == 'REVIEW':
                        self.stats['review'] += 1
                    else:
                        self.stats['rejected'] += 1
                    
                    logger.info(f"âœ… {project['name']}: {result['verdict']} ({result['score']:.1f}/100)")
                    
                    await asyncio.sleep(self.api_delay)
                
                except Exception as e:
                    logger.error(f"âŒ Erreur {project.get('name', 'Unknown')}: {e}")
                    logger.error(traceback.format_exc())
            
            scan_end = datetime.now()
            conn = sqlite3.connect('quantum.db')
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO scan_history (
                    scan_start, scan_end, projects_found,
                    projects_accepted, projects_rejected, projects_review, scam_blocked
                )
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                scan_start, scan_end, self.stats['projects_found'],
                self.stats['accepted'], self.stats['rejected'],
                self.stats['review'], self.stats['scam_blocked']
            ))
            conn.commit()
            conn.close()
            
            duration = (scan_end - scan_start).total_seconds()
            logger.info(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    SCAN TERMINÃ‰                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Projets: {self.stats['projects_found']:>4} | âœ… {self.stats['accepted']:>2} | âš ï¸ {self.stats['review']:>2} | âŒ {self.stats['rejected']:>3}     â•‘
â•‘  Scams bloquÃ©s: {self.stats['scam_blocked']:>2} | Alertes: {self.stats['alerts_sent']:>2} | Temps: {duration:>5.0f}s       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            """)
        
        except Exception as e:
            logger.error(f"âŒ ERREUR CRITIQUE: {e}")
            logger.error(traceback.format_exc())


# ============================================================================
# MAIN
# ============================================================================

async def main(args):
    """Main"""
    scanner = QuantumScanner()
    
    if args.once:
        logger.info("Mode: Scan unique")
        await scanner.scan()
    elif args.daemon:
        logger.info(f"Mode: Daemon {scanner.scan_interval}h")
        while True:
            await scanner.scan()
            logger.info(f"â¸ï¸ Pause {scanner.scan_interval}h...")
            await asyncio.sleep(scanner.scan_interval * 3600)
    elif args.test_project:
        logger.info(f"Mode: Test {args.test_project}")
        project = {
            "name": args.test_project,
            "symbol": "TEST",
            "source": "Manual",
            "link": args.test_project if args.test_project.startswith('http') else None,
        }
        result = await scanner.verify_project_complete(project)
        print(json.dumps(result, indent=2, default=str))
    else:
        logger.error("âŒ Utilisez --once, --daemon, ou --test-project")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Quantum Scanner v16.1')
    parser.add_argument('--once', action='store_true', help='Scan unique')
    parser.add_argument('--daemon', action='store_true', help='Mode 24/7')
    parser.add_argument('--test-project', type=str, help='Test projet')
    parser.add_argument('--github-actions', action='store_true', help='CI/CD')
    parser.add_argument('--verbose', action='store_true', help='Debug')
    
    args = parser.parse_args()
    
    if args.verbose:
        logger.remove()
        logger.add(lambda msg: print(msg, end=''), level="DEBUG")
    
    asyncio.run(main(args))