#!/usr/bin/env python3
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              QUANTUM SCANNER ULTIME v16.0 MAXIMUM                        ‚ïë
‚ïë              30+ SOURCES + 21 RATIOS + CALCULS COMPLETS                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import asyncio
import aiohttp
import sqlite3
import os
import re
from datetime import datetime
from typing import Dict, List, Optional
from loguru import logger
from dotenv import load_dotenv
from telegram import Bot
from bs4 import BeautifulSoup
from web3 import Web3

load_dotenv()
logger.add("logs/quantum_{time:YYYY-MM-DD}.log", rotation="1 day", retention="30 days", compression="zip")

# Projets r√©f√©rence (devenus p√©pites)
REFERENCE_PROJECTS = {
    "solana": {"mc_fdmc": 0.15, "vc_score": 1.0, "audit_score": 1.0, "dev_activity": 0.9, "community": 0.85, "multiplier": 250},
    "polygon": {"mc_fdmc": 0.20, "vc_score": 0.9, "audit_score": 0.9, "dev_activity": 0.85, "community": 0.80, "multiplier": 150},
    "avalanche": {"mc_fdmc": 0.18, "vc_score": 0.95, "audit_score": 0.9, "dev_activity": 0.80, "community": 0.75, "multiplier": 100},
    "near": {"mc_fdmc": 0.22, "vc_score": 0.85, "audit_score": 0.85, "dev_activity": 0.75, "community": 0.70, "multiplier": 80},
    "ftm": {"mc_fdmc": 0.25, "vc_score": 0.80, "audit_score": 0.80, "dev_activity": 0.70, "community": 0.65, "multiplier": 60},
}

TIER1_AUDITORS = ["CertiK", "PeckShield", "SlowMist", "Quantstamp", "OpenZeppelin", "Hacken", "Trail of Bits", "ConsenSys Diligence"]
TIER1_VCS = ["Binance Labs", "Coinbase Ventures", "Sequoia Capital", "a16z", "Paradigm", "Polychain", "Pantera Capital", 
             "Dragonfly Capital", "Multicoin Capital", "Alameda Research", "Jump Crypto", "Galaxy Digital"]

# Poids des 21 ratios
RATIO_WEIGHTS = {
    "mc_fdmc": 0.15,           # Valorisation MC/FDV
    "circ_vs_total": 0.08,     # Supply circulant vs total
    "volume_mc": 0.07,          # Volume vs MC
    "liquidity_ratio": 0.12,    # Liquidit√©
    "whale_concentration": 0.10, # Concentration baleines
    "audit_score": 0.10,        # Score audit
    "vc_score": 0.08,           # Score VCs
    "social_sentiment": 0.05,   # Sentiment social
    "dev_activity": 0.06,       # Activit√© dev
    "market_sentiment": 0.03,   # Sentiment march√©
    "tokenomics_health": 0.04,  # Sant√© tokenomics
    "vesting_score": 0.03,      # Score vesting
    "exchange_listing_score": 0.02, # Listings exchanges
    "community_growth": 0.04,   # Croissance communaut√©
    "partnership_quality": 0.02, # Qualit√© partenariats
    "product_maturity": 0.03,   # Maturit√© produit
    "revenue_generation": 0.02, # G√©n√©ration revenus
    "volatility": 0.02,         # Volatilit√©
    "correlation": 0.01,        # Corr√©lation march√©
    "historical_performance": 0.02, # Performance historique
    "risk_adjusted_return": 0.01,   # Retour ajust√© risque
}


class QuantumScanner:
    def __init__(self):
        logger.info("üåå Quantum Scanner ULTIME v16.0 - MAXIMUM")
        
        self.telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        self.chat_review = os.getenv('TELEGRAM_CHAT_REVIEW')
        self.go_score = float(os.getenv('GO_SCORE', 60))
        self.review_score = float(os.getenv('REVIEW_SCORE', 30))
        self.max_mc = float(os.getenv('MAX_MARKET_CAP_EUR', 10_000_000))
        
        self.telegram_bot = Bot(token=self.telegram_token)
        
        try:
            self.w3_eth = Web3(Web3.HTTPProvider(os.getenv('INFURA_URL', 'https://mainnet.infura.io/v3/')))
            self.w3_bsc = Web3(Web3.HTTPProvider('https://bsc-dataseed.binance.org/'))
        except:
            self.w3_eth = None
            self.w3_bsc = None
        
        self.init_db()
        self.stats = {"projects_found": 0, "accepted": 0, "rejected": 0, "review": 0, "alerts_sent": 0}
        
        logger.info("‚úÖ Scanner initialis√© - Mode MAXIMUM activ√©")
    
    def init_db(self):
        os.makedirs("logs", exist_ok=True)
        os.makedirs("results", exist_ok=True)
        
        conn = sqlite3.connect('quantum.db')
        cursor = conn.cursor()
        
        # Table projects compl√®te
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS projects (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                symbol TEXT,
                source TEXT,
                link TEXT,
                verdict TEXT,
                score REAL,
                go_reason TEXT,
                twitter TEXT,
                telegram TEXT,
                discord TEXT,
                github TEXT,
                hard_cap_usd REAL,
                ico_price_usd REAL,
                total_supply REAL,
                fmv REAL,
                current_mc REAL,
                backers TEXT,
                audit_firms TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(name, source)
            )
        ''')
        
        # Table ratios (21 ratios)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ratios (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                project_id INTEGER NOT NULL,
                mc_fdmc REAL,
                circ_vs_total REAL,
                volume_mc REAL,
                liquidity_ratio REAL,
                whale_concentration REAL,
                audit_score REAL,
                vc_score REAL,
                social_sentiment REAL,
                dev_activity REAL,
                market_sentiment REAL,
                tokenomics_health REAL,
                vesting_score REAL,
                exchange_listing_score REAL,
                community_growth REAL,
                partnership_quality REAL,
                product_maturity REAL,
                revenue_generation REAL,
                volatility REAL,
                correlation REAL,
                historical_performance REAL,
                risk_adjusted_return REAL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES projects(id)
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("‚úÖ DB initialis√©e avec tables compl√®tes")
    
    async def fetch_source(self, name: str, url: str) -> List[Dict]:
        """Scraper g√©n√©rique optimis√©"""
        projects = []
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=12, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}) as resp:
                    if resp.status == 200:
                        html = await resp.text()
                        soup = BeautifulSoup(html, 'lxml')
                        text = soup.get_text()
                        
                        # Extraire tokens (3-10 lettres)
                        tokens = re.findall(r'\b([A-Z]{3,10})\b', text)
                        exclude = {'TOKEN', 'SALE', 'IDO', 'ICO', 'LAUNCH', 'NEW', 'BUY', 'SELL', 'TRADE',
                                   'USD', 'BTC', 'ETH', 'BNB', 'USDT', 'BUSD', 'USDC', 'DAI', 'SOL', 
                                   'LINK', 'UNI', 'MATIC', 'AVAX', 'DOT', 'ADA', 'XRP', 'DOGE', 'SHIB',
                                   'APR', 'APY', 'TVL', 'DEX', 'CEX', 'DeFi', 'NFT', 'DAO', 'TGE'}
                        
                        seen = set()
                        for token in tokens:
                            if token not in exclude and token not in seen and len(token) >= 3:
                                seen.add(token)
                                projects.append({
                                    "name": token,
                                    "symbol": token,
                                    "source": name,
                                    "link": url,
                                })
                                if len(projects) >= 30:  # Max 30 par source
                                    break
            
            logger.info(f"‚úÖ {name}: {len(projects)} projets")
        except Exception as e:
            logger.error(f"‚ùå {name}: {e}")
        
        return projects
    
    async def fetch_all_sources(self) -> List[Dict]:
        """30+ sources en parall√®le"""
        logger.info("üîç Scan 30+ sources en parall√®le...")
        
        sources = [
            # TOP CEX LAUNCHPADS
            ("CoinList", "https://coinlist.co/token-launches"),
            ("Binance Launchpad", "https://www.binance.com/en/launchpad"),
            ("Binance Megadrop", "https://www.binance.com/en/megadrop"),
            ("Bybit Launchpad", "https://www.bybit.com/en-US/web3/launchpad"),
            ("OKX Jumpstart", "https://www.okx.com/jumpstart"),
            ("Gate.io Startup", "https://www.gate.io/startup"),
            ("KuCoin Spotlight", "https://www.kucoin.com/spotlight"),
            ("Huobi Prime", "https://www.htx.com/en-us/prime"),
            ("Bitget Launchpad", "https://www.bitget.com/launchpad"),
            ("MEXC Launchpad", "https://www.mexc.com/launchpad"),
            
            # AGGREGATORS
            ("CoinMarketCap New", "https://coinmarketcap.com/new/"),
            ("CoinGecko New", "https://www.coingecko.com/en/coins/recently_added"),
            ("CoinGecko Trending", "https://www.coingecko.com/en/coins/trending"),
            ("CryptoRank ICO", "https://cryptorank.io/ico"),
            ("ICODrops Active", "https://icodrops.com/category/active-ico/"),
            ("ICOBench", "https://icobench.com/icos"),
            ("TokenInsight", "https://tokeninsight.com/en/tokensale"),
            
            # DEFI LAUNCHPADS
            ("Polkastarter", "https://www.polkastarter.com/projects"),
            ("DAO Maker", "https://daomaker.com/sho"),
            ("Seedify", "https://launchpad.seedify.fund/"),
            ("TrustPad", "https://trustpad.io/projects"),
            ("BSCPad", "https://bscpad.com/projects"),
            ("GameFi", "https://gamefi.org/launchpad"),
            ("Red Kite", "https://redkite.polkafoundry.com/#/projects"),
            ("Occam", "https://occam.fi/launchpad"),
            ("Enjinstarter", "https://enjinstarter.com/projects"),
            ("Kommunitas", "https://kommunitas.net/projects"),
            
            # DEX & TRADING
            ("Uniswap New", "https://info.uniswap.org/#/pools"),
            ("PancakeSwap New", "https://pancakeswap.finance/info/pairs"),
            ("DexTools Hot", "https://www.dextools.io/app/en/hot-pairs"),
            ("DexScreener", "https://dexscreener.com/"),
        ]
        
        # Fetch parallel avec timeout global
        tasks = [self.fetch_source(name, url) for name, url in sources]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Flatten + dedupe
        all_projects = []
        for result in results:
            if isinstance(result, list):
                all_projects.extend(result)
        
        # D√©duplication intelligente
        seen = set()
        unique = []
        for p in all_projects:
            key = (p['symbol'], p['source'])
            if key not in seen:
                seen.add(key)
                unique.append(p)
        
        logger.info(f"üìä {len(unique)} projets uniques depuis {len(sources)} sources")
        return unique
    
    async def fetch_project_complete_data(self, project: Dict) -> Dict:
        """Scraper TOUTES les donn√©es possibles"""
        data = {
            "twitter": None, "telegram": None, "discord": None, "reddit": None, "github": None,
            "website": None, "whitepaper": None,
            "hard_cap_usd": None, "ico_price_usd": None, "sale_price_usd": None,
            "total_supply": None, "circulating_supply": None, "initial_supply": None,
            "fmv": None, "current_mc": None, "initial_mc": None,
            "vesting_months": None, "lock_period_months": None,
            "backers": [], "audit_firms": [], "partners": [], "team_members": [],
            "twitter_followers": 0, "telegram_members": 0, "discord_members": 0,
            "github_commits": 0, "github_stars": 0,
            "contract_address": None, "chain": None,
            "listing_date": None, "tge_date": None,
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(project['link'], timeout=15, headers={'User-Agent': 'Mozilla/5.0'}) as resp:
                    if resp.status == 200:
                        html = await resp.text()
                        soup = BeautifulSoup(html, 'lxml')
                        text = soup.get_text()
                        
                        # LIENS SOCIAUX
                        links = soup.find_all('a', href=True)
                        for link in links:
                            href = link.get('href', '').lower()
                            if 'twitter.com' in href or 'x.com' in href:
                                data['twitter'] = link.get('href')
                            elif 't.me' in href or 'telegram' in href:
                                data['telegram'] = link.get('href')
                            elif 'discord' in href:
                                data['discord'] = link.get('href')
                            elif 'reddit.com' in href:
                                data['reddit'] = link.get('href')
                            elif 'github.com' in href:
                                data['github'] = link.get('href')
                            elif '.pdf' in href or 'whitepaper' in href.lower():
                                data['whitepaper'] = link.get('href')
                        
                        # FINANCIERS
                        # Hard cap
                        hardcap_patterns = [
                            r'\$?([\d,.]+)\s*(million|M|m)\s*(?:hard\s*cap|raise|raised|target)',
                            r'(?:hard\s*cap|raise|target)[\s:]*\$?([\d,.]+)\s*(million|M|m)?',
                        ]
                        for pattern in hardcap_patterns:
                            match = re.search(pattern, text, re.I)
                            if match:
                                num = float(match.group(1).replace(',', ''))
                                unit = (match.group(2) or '').lower()
                                if 'm' in unit or 'million' in unit:
                                    num *= 1_000_000
                                data['hard_cap_usd'] = num
                                break
                        
                        # Prix ICO/Sale
                        price_patterns = [
                            r'\$?([\d.]+)\s*(?:per\s*token|price|sale\s*price)',
                            r'(?:price|token\s*price)[\s:]*\$?([\d.]+)',
                        ]
                        for pattern in price_patterns:
                            match = re.search(pattern, text, re.I)
                            if match:
                                data['ico_price_usd'] = float(match.group(1))
                                break
                        
                        # Supply
                        supply_patterns = [
                            r'([\d,]+\.?\d*)\s*(billion|million|B|M)\s*(?:total\s*)?supply',
                            r'(?:total\s*)?supply[\s:]*([\\d,]+\.?\d*)\s*(billion|million|B|M)?',
                        ]
                        for pattern in supply_patterns:
                            match = re.search(pattern, text, re.I)
                            if match:
                                num = float(match.group(1).replace(',', ''))
                                unit = (match.group(2) or '').lower()
                                if 'b' in unit or 'billion' in unit:
                                    num *= 1_000_000_000
                                elif 'm' in unit or 'million' in unit:
                                    num *= 1_000_000
                                data['total_supply'] = num
                                break
                        
                        # Circulating supply (%)
                        circ_patterns = [
                            r'([\d.]+)%?\s*(?:circulating|initial|unlock|tge)',
                            r'(?:circulating|initial|unlock)[\s:]*([\\d.]+)%?',
                        ]
                        for pattern in circ_patterns:
                            match = re.search(pattern, text, re.I)
                            if match and data['total_supply']:
                                pct = float(match.group(1))
                                if pct > 1:  # Si en pourcentage
                                    pct /= 100
                                data['circulating_supply'] = data['total_supply'] * pct
                                break
                        
                        # Vesting
                        vesting_match = re.search(r'([\d]+)\s*(?:month|year|yr)\s*(?:vesting|lock|cliff)', text, re.I)
                        if vesting_match:
                            months = int(vesting_match.group(1))
                            if 'year' in vesting_match.group(0).lower() or 'yr' in vesting_match.group(0).lower():
                                months *= 12
                            data['vesting_months'] = months
                        
                        # BACKERS (VCs Tier1)
                        for vc in TIER1_VCS:
                            if vc.lower() in text.lower():
                                data['backers'].append(vc)
                        
                        # AUDIT
                        for auditor in TIER1_AUDITORS:
                            if auditor.lower() in text.lower():
                                data['audit_firms'].append(auditor)
                        
                        # CALCULS D√âRIV√âS
                        if data['ico_price_usd'] and data['total_supply']:
                            data['fmv'] = data['ico_price_usd'] * data['total_supply']
                        
                        if data['ico_price_usd'] and data['circulating_supply']:
                            data['current_mc'] = data['ico_price_usd'] * data['circulating_supply']
                        
        except Exception as e:
            logger.error(f"‚ùå Fetch complete data error for {project['name']}: {e}")
        
        return data
    
    def calculate_all_21_ratios(self, data: Dict) -> Dict:
        """Calcul COMPLET des 21 ratios"""
        ratios = {}
        
        # Ratio 1: MC/FDV (plus c'est bas, mieux c'est)
        if data.get('current_mc') and data.get('fmv') and data['fmv'] > 0:
            mc_fdmc_raw = data['current_mc'] / data['fmv']
            # Inverser: 0.1 excellent, 0.3 bon, 0.5 moyen, 0.8+ mauvais
            ratios['mc_fdmc'] = max(0, min(1.0, 1.0 - mc_fdmc_raw))
        else:
            ratios['mc_fdmc'] = 0.5
        
        # Ratio 2: Circ vs Total supply
        if data.get('circulating_supply') and data.get('total_supply') and data['total_supply'] > 0:
            circ_pct = data['circulating_supply'] / data['total_supply']
            # 0.2-0.3 = optimal (pas trop dilu√©, pas trop concentr√©)
            if 0.15 <= circ_pct <= 0.35:
                ratios['circ_vs_total'] = 1.0
            else:
                ratios['circ_vs_total'] = max(0, 1.0 - abs(circ_pct - 0.25) * 2)
        else:
            ratios['circ_vs_total'] = 0.5
        
        # Ratio 3: Volume/MC (assume donn√©es manquantes)
        ratios['volume_mc'] = 0.5
        
        # Ratio 4: Liquidit√©
        if data.get('hard_cap_usd') and data.get('current_mc') and data['current_mc'] > 0:
            liq_ratio = data['hard_cap_usd'] / data['current_mc']
            ratios['liquidity_ratio'] = min(liq_ratio / 2, 1.0)  # 50%+ = excellent
        else:
            ratios['liquidity_ratio'] = 0.4
        
        # Ratio 5: Whale concentration (assume donn√©es manquantes)
        ratios['whale_concentration'] = 0.6
        
        # Ratio 6: Audit score
        num_audits = len(data.get('audit_firms', []))
        if num_audits >= 2:
            ratios['audit_score'] = 1.0
        elif num_audits == 1:
            ratios['audit_score'] = 0.7
        else:
            ratios['audit_score'] = 0.3
        
        # Ratio 7: VC score
        num_vcs = len(data.get('backers', []))
        if num_vcs >= 3:
            ratios['vc_score'] = 1.0
        elif num_vcs == 2:
            ratios['vc_score'] = 0.8
        elif num_vcs == 1:
            ratios['vc_score'] = 0.5
        else:
            ratios['vc_score'] = 0.2
        
        # Ratio 8: Social sentiment
        twitter = data.get('twitter_followers', 0)
        telegram = data.get('telegram_members', 0)
        total_social = twitter + telegram
        if total_social >= 50000:
            ratios['social_sentiment'] = 1.0
        elif total_social >= 10000:
            ratios['social_sentiment'] = 0.7
        else:
            ratios['social_sentiment'] = min(total_social / 10000, 1.0)
        
        # Ratio 9: Dev activity
        github_commits = data.get('github_commits', 0)
        if github_commits >= 200:
            ratios['dev_activity'] = 1.0
        elif github_commits >= 50:
            ratios['dev_activity'] = 0.7
        elif data.get('github'):
            ratios['dev_activity'] = 0.5
        else:
            ratios['dev_activity'] = 0.2
        
        # Ratio 10: Market sentiment (assume neutre)
        ratios['market_sentiment'] = 0.55
        
        # Ratio 11: Tokenomics health (bas√© sur vesting)
        vesting = data.get('vesting_months', 0)
        if vesting >= 24:
            ratios['tokenomics_health'] = 1.0
        elif vesting >= 12:
            ratios['tokenomics_health'] = 0.7
        else:
            ratios['tokenomics_health'] = 0.4
        
        # Ratio 12: Vesting score (similaire mais invers√©)
        ratios['vesting_score'] = ratios['tokenomics_health']
        
        # Ratio 13: Exchange listing (assume aucun listing encore)
        ratios['exchange_listing_score'] = 0.3
        
        # Ratio 14: Community growth (bas√© sur social)
        ratios['community_growth'] = ratios['social_sentiment']
        
        # Ratio 15: Partnership quality (bas√© sur backers)
        if num_vcs >= 2 or num_audits >= 1:
            ratios['partnership_quality'] = 0.8
        elif num_vcs >= 1:
            ratios['partnership_quality'] = 0.5
        else:
            ratios['partnership_quality'] = 0.3
        
        # Ratio 16: Product maturity (bas√© sur whitepaper + github)
        has_wp = bool(data.get('whitepaper'))
        has_gh = bool(data.get('github'))
        if has_wp and has_gh:
            ratios['product_maturity'] = 0.8
        elif has_wp or has_gh:
            ratios['product_maturity'] = 0.5
        else:
            ratios['product_maturity'] = 0.3
        
        # Ratios 17-21: Assumes valeurs neutres/conservatrices
        ratios['revenue_generation'] = 0.3
        ratios['volatility'] = 0.6
        ratios['correlation'] = 0.5
        ratios['historical_performance'] = 0.4
        ratios['risk_adjusted_return'] = 0.5
        
        return ratios
    
    def compare_to_gem_references(self, ratios: Dict) -> Optional[tuple]:
        """Comparer aux projets devenus p√©pites"""
        similarities = {}
        
        for ref_name, ref_data in REFERENCE_PROJECTS.items():
            total_diff = 0
            count = 0
            
            # Comparer sur les ratios cl√©s
            for key in ['mc_fdmc', 'vc_score', 'audit_score', 'dev_activity']:
                if key in ratios and key in ref_data:
                    diff = abs(ratios[key] - ref_data[key])
                    total_diff += diff
                    count += 1
            
            if count > 0:
                similarity = 1.0 - (total_diff / count)
                similarities[ref_name] = {
                    "similarity": similarity,
                    "multiplier": ref_data['multiplier']
                }
        
        if not similarities:
            return None
        
        best_match = max(similarities.items(), key=lambda x: x[1]['similarity'])
        return best_match
    
    async def verify_project_complete(self, project: Dict) -> Dict:
        """V√©rification COMPL√àTE avec 21 ratios"""
        
        # 1. Fetch toutes les donn√©es
        data = await self.fetch_project_complete_data(project)
        project.update(data)
        
        # 2. Calculer les 21 ratios
        ratios = self.calculate_all_21_ratios(data)
        
        # 3. Comparer aux p√©pites
        best_match = self.compare_to_gem_references(ratios)
        
        # 4. Score final pond√©r√©
        score = sum(ratios.get(k, 0) * v for k, v in RATIO_WEIGHTS.items()) * 100
        score = min(100, max(0, score))
        
        # 5. Analyse GO/NO GO intelligente
        go_reason = ""
        flags = []
        
        if best_match:
            ref_name, ref_info = best_match
            similarity_pct = ref_info['similarity'] * 100
            multiplier = ref_info['multiplier']
            
            if similarity_pct >= 70:
                go_reason = f"üéØ **PROFIL SIMILAIRE √Ä {ref_name.upper()} ({similarity_pct:.0f}% match)** qui a fait x{multiplier}. "
                flags.append('similar_to_gem')
            elif similarity_pct >= 50:
                go_reason = f"‚ö†Ô∏è Profil proche de {ref_name} ({similarity_pct:.0f}% match, x{multiplier}). "
        
        # Analyse ratios cl√©s
        if ratios.get('mc_fdmc', 0) > 0.7:
            go_reason += "‚úÖ Valorisation attractive (MC/FDV faible). "
            flags.append('good_valuation')
        
        if ratios.get('vc_score', 0) >= 0.7:
            go_reason += f"‚úÖ VCs Tier1 ({len(data.get('backers', []))}). "
            flags.append('tier1_vcs')
        
        if ratios.get('audit_score', 0) >= 0.7:
            go_reason += f"‚úÖ Audit v√©rifi√© ({len(data.get('audit_firms', []))}). "
            flags.append('audited')
        
        if ratios.get('dev_activity', 0) >= 0.7:
            go_reason += "‚úÖ Dev actif. "
            flags.append('active_dev')
        
        if ratios.get('community_growth', 0) >= 0.7:
            go_reason += "‚úÖ Forte communaut√©. "
            flags.append('strong_community')
        
        # Warnings
        if ratios.get('dev_activity', 0) < 0.3:
            go_reason += "‚ö†Ô∏è Dev activity faible. "
            flags.append('low_dev')
        
        if ratios.get('audit_score', 0) < 0.5:
            go_reason += "‚ö†Ô∏è Pas d'audit. "
            flags.append('no_audit')
        
        # Verdict final
        if score >= self.go_score and best_match and best_match[1]['similarity'] >= 0.6:
            verdict = "ACCEPT"
            go_reason = "üöÄ **GO !** " + go_reason
        elif score >= self.review_score:
            verdict = "REVIEW"
        else:
            verdict = "REJECT"
            go_reason = "‚ùå **NO GO.** " + go_reason
        
        return {
            "verdict": verdict,
            "score": score,
            "ratios": ratios,
            "go_reason": go_reason,
            "best_match": best_match,
            "data": data,
            "flags": flags,
        }
    
    async def send_telegram_complete(self, project: Dict, result: Dict):
        """Message Telegram ULTRA COMPLET"""
        verdict_emoji = "‚úÖ" if result['verdict'] == "ACCEPT" else "‚ö†Ô∏è" if result['verdict'] == "REVIEW" else "‚ùå"
        risk_level = "Faible" if result['score'] >= 75 else "Moyen" if result['score'] >= 50 else "√âlev√©"
        
        data = result.get('data', {})
        ratios = result.get('ratios', {})
        
        # Top 7 ratios
        ratios_sorted = sorted(ratios.items(), key=lambda x: x[1], reverse=True)[:7]
        top_ratios_text = "\n".join([
            f"{i+1}. {k.replace('_', ' ').title()}: {v*100:.0f}% (poids {RATIO_WEIGHTS.get(k, 0)*100:.0f}%)"
            for i, (k, v) in enumerate(ratios_sorted)
        ])
        
        # Backers
        backers = data.get('backers', [])
        backers_text = ", ".join(backers) if backers else "N/A"
        
        # Audits
        audits = data.get('audit_firms', [])
        audits_text = ", ".join(audits) if audits else "Aucun"
        
        # Match r√©f√©rence
        match_text = "N/A"
        if result.get('best_match'):
            ref_name, ref_info = result['best_match']
            match_text = f"{ref_name.upper()} ({ref_info['similarity']*100:.0f}% match, x{ref_info['multiplier']})"
        
        message = f"""
üåå **QUANTUM v16.0 ULTIME ‚Äî {project['name']} ({project['symbol']})**

üìä **SCORE: {result['score']:.1f}/100** | {verdict_emoji} **{result['verdict']}**
‚ö†Ô∏è **RISQUE:** {risk_level}

---
üí° **ANALYSE INTELLIGENTE:**
{result['go_reason']}

üéØ **PROFIL PROCHE DE:** {match_text}

---
üí∞ **FINANCIERS (R√âELS):**
‚Ä¢ Hard Cap: ${data.get('hard_cap_usd', 0):,.0f}
‚Ä¢ Prix ICO: ${data.get('ico_price_usd', 0):.6f}
‚Ä¢ Total Supply: {data.get('total_supply', 0):,.0f}
‚Ä¢ FDV: ${data.get('fmv', 0):,.0f}
‚Ä¢ MC Initial: ${data.get('current_mc', 0):,.0f}
‚Ä¢ **MC/FDV: {(data.get('current_mc', 1) / max(data.get('fmv', 1), 1))*100:.1f}%** {"‚úÖ" if ratios.get('mc_fdmc', 0) > 0.7 else "‚ö†Ô∏è"}

---
üìä **TOP 7 RATIOS (sur 21):**
{top_ratios_text}

---
üîí **S√âCURIT√â & BACKING:**
‚Ä¢ **Audits:** {audits_text}
‚Ä¢ **Backers:** {backers_text}
‚Ä¢ **Vesting:** {data.get('vesting_months', 0)} mois

---
üìà **SCORES PAR CAT√âGORIE:**
‚Ä¢ Valorisation: {ratios.get('mc_fdmc', 0)*100:.0f}%
‚Ä¢ S√©curit√©: {ratios.get('audit_score', 0)*100:.0f}%
‚Ä¢ Backing: {ratios.get('vc_score', 0)*100:.0f}%
‚Ä¢ Dev Activity: {ratios.get('dev_activity', 0)*100:.0f}%
‚Ä¢ Communaut√©: {ratios.get('community_growth', 0)*100:.0f}%
‚Ä¢ Tokenomics: {ratios.get('tokenomics_health', 0)*100:.0f}%

---
üì± **SOCIALS:**
‚Ä¢ Twitter: {data.get('twitter') or 'N/A'} ({data.get('twitter_followers', 0):,} followers)
‚Ä¢ Telegram: {data.get('telegram') or 'N/A'}
‚Ä¢ Discord: {data.get('discord') or 'N/A'}
‚Ä¢ GitHub: {data.get('github') or 'N/A'}

---
üöÄ **SOURCE:** {project['source']}
üîó **LAUNCHPAD:** {project.get('link', 'N/A')}
üìÑ **WHITEPAPER:** {data.get('whitepaper') or 'N/A'}

---
‚ö†Ô∏è **FLAGS:** {', '.join(result.get('flags', [])) or 'Aucun'}

---
üìå **DISCLAIMER:** Projet early-stage √† haut risque. DYOR. Pas de conseil financier.

_Scan ID: {datetime.now().strftime('%Y%m%d_%H%M%S')} | 21 ratios calcul√©s_
"""
        
        try:
            # Envoyer selon verdict
            target_chat = self.chat_id if result['verdict'] == 'ACCEPT' else self.chat_review
            await self.telegram_bot.send_message(target_chat, message, parse_mode='Markdown')
            logger.info(f"‚úÖ Telegram envoy√©: {project['name']} ({result['verdict']})")
            self.stats['alerts_sent'] += 1
        except Exception as e:
            logger.error(f"‚ùå Telegram error for {project['name']}: {e}")
    
    def save_project_complete(self, project: Dict, result: Dict):
        """Sauvegarder projet + 21 ratios"""
        try:
            conn = sqlite3.connect('quantum.db')
            cursor = conn.cursor()
            
            data = result.get('data', {})
            
            # Insert project
            cursor.execute('''
                INSERT OR REPLACE INTO projects (
                    name, symbol, source, link, verdict, score, go_reason,
                    twitter, telegram, discord, github,
                    hard_cap_usd, ico_price_usd, total_supply, fmv, current_mc,
                    backers, audit_firms
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                project['name'], project.get('symbol'), project['source'], project.get('link'),
                result['verdict'], result['score'], result['go_reason'],
                data.get('twitter'), data.get('telegram'), data.get('discord'), data.get('github'),
                data.get('hard_cap_usd'), data.get('ico_price_usd'), data.get('total_supply'),
                data.get('fmv'), data.get('current_mc'),
                ','.join(data.get('backers', [])), ','.join(data.get('audit_firms', []))
            ))
            
            project_id = cursor.lastrowid
            
            # Insert 21 ratios
            ratios = result.get('ratios', {})
            cursor.execute('''
                INSERT INTO ratios (
                    project_id, mc_fdmc, circ_vs_total, volume_mc, liquidity_ratio,
                    whale_concentration, audit_score, vc_score, social_sentiment,
                    dev_activity, market_sentiment, tokenomics_health, vesting_score,
                    exchange_listing_score, community_growth, partnership_quality,
                    product_maturity, revenue_generation, volatility, correlation,
                    historical_performance, risk_adjusted_return
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                project_id,
                ratios.get('mc_fdmc'), ratios.get('circ_vs_total'), ratios.get('volume_mc'),
                ratios.get('liquidity_ratio'), ratios.get('whale_concentration'),
                ratios.get('audit_score'), ratios.get('vc_score'), ratios.get('social_sentiment'),
                ratios.get('dev_activity'), ratios.get('market_sentiment'),
                ratios.get('tokenomics_health'), ratios.get('vesting_score'),
                ratios.get('exchange_listing_score'), ratios.get('community_growth'),
                ratios.get('partnership_quality'), ratios.get('product_maturity'),
                ratios.get('revenue_generation'), ratios.get('volatility'),
                ratios.get('correlation'), ratios.get('historical_performance'),
                ratios.get('risk_adjusted_return')
            ))
            
            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"‚ùå DB error: {e}")
    
    async def scan(self):
        logger.info("üöÄ SCAN ULTIME MAXIMUM - 30+ sources + 21 ratios")
        
        # Fetch depuis 30+ sources
        projects = await self.fetch_all_sources()
        self.stats['projects_found'] = len(projects)
        
        logger.info(f"üìä Analyse de {len(projects)} projets avec 21 ratios chacun...")
        
        for i, project in enumerate(projects, 1):
            try:
                logger.info(f"üîç [{i}/{len(projects)}] Analyse: {project['name']}...")
                
                # V√©rification compl√®te (21 ratios + analyse)
                result = await self.verify_project_complete(project)
                
                # Sauvegarder en DB
                self.save_project_complete(project, result)
                
                # ENVOYER TOUTES LES ALERTES
                await self.send_telegram_complete(project, result)
                
                # Stats
                verdict_key = result['verdict'].lower()
                if verdict_key == 'reject':
                    verdict_key = 'rejected'
                elif verdict_key == 'accept':
                    verdict_key = 'accepted'
                self.stats[verdict_key] += 1
                
                # Rate limit (max 30 msg/sec Telegram)
                await asyncio.sleep(0.05)
                
            except Exception as e:
                logger.error(f"‚ùå Erreur projet {project.get('name', 'Unknown')}: {e}")
                continue
        
        logger.info(f"‚úÖ SCAN TERMIN√â: {self.stats}")
        logger.info(f"üì® {self.stats['alerts_sent']} alertes envoy√©es sur {self.stats['projects_found']} projets")


async def main(args):
    scanner = QuantumScanner()
    if args.once:
        await scanner.scan()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Quantum Scanner v16.0 ULTIME')
    parser.add_argument('--once', action='store_true', help='Run once')
    args = parser.parse_args()
    
    asyncio.run(main(args))
